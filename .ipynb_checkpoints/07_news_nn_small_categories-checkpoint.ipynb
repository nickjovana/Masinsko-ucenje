{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import linear_model\n",
    "from sklearn import multiclass\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Conv1D, MaxPool1D, GlobalMaxPool1D, Activation, SpatialDropout1D, LSTM, SimpleRNN, GRU\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras import losses, optimizers\n",
    "from keras import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izvršićemo klasifikaciju podataka neurnoskim mrežama za 2 kategorije. Učitaćemo podatke i odraditi vektorizaciju, a zatim podeliti na podatke na trening, test i validacione skupove. Isprobavali smo različite vrednosti za parametre modela (units, epochs, batch_size, learning_rate) kao i broj slojeva i za ove vrednosti smo dobili najbolje moguće modele za naše podatke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija <i>GetData</i> će nam služiti za učitavanje podataka u zavisnosti od broja kategorija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetData(num_of_categories, categories):\n",
    "    news = pd.read_csv('data/vesti.csv')\n",
    "    if num_of_categories == 36:\n",
    "        X = news['text']\n",
    "        y = news['category']\n",
    "    else:\n",
    "        news = news[news.category.isin(categories)]\n",
    "        X = news['text']\n",
    "        y = news['category']\n",
    "        \n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija <i>EvaluateModel</i> će služiti za evaluaciju podataka na test skupu i vizualizaciju dobijenih vrednosti funkcije greške i tačnosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateModel(model, X_test, y_test, history):\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print('Test loss: ', score[0])\n",
    "    print('Test accuracy: ', score[1])\n",
    "    \n",
    "    epochs = history.epoch\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "    \n",
    "    accuracy = history.history['accuracy']\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(epochs, loss, c='red', label = 'training')\n",
    "    plt.plot(epochs, validation_loss, c='orange', label='validation')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.plot(epochs, accuracy, c='red', label = 'training')\n",
    "    plt.plot(epochs, validation_accuracy, c = 'orange', label = 'validation')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija <i>TransformToTensor</i> izvrsava dekompoziciju pomocu TruncatedSVD algoritma i proveravamo variansu kako bismo ocuvali smisao podataka, zatim na kraju pretvaramo transformisane podatke u tenzor kako bismo mogli da pokrenemo modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformToTensor(X, n):\n",
    "    pca = decomposition.TruncatedSVD(n_components=n, random_state=4)\n",
    "    pca.fit(X)\n",
    "    print(sum(pca.explained_variance_ratio_))\n",
    "    X = pca.transform(X)\n",
    "    return tf.convert_to_tensor(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikacija za 2 kategorije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Učitavamo podatke za dve kategorije koje imaju najveći broj članaka u skupu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8239,)\n",
      "(8239,)\n"
     ]
    }
   ],
   "source": [
    "categories2 = ['SPORTS', 'WOMEN']\n",
    "X2, y2 = GetData(2, categories2)\n",
    "print(X2.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delimo podatke na trening, test i validacioni skup, a zatim ih transformišemo pomoću funkcije TransformData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X2, y2, test_size = 0.2, stratify = y2, random_state = 4)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_validation, y_train_validation, test_size = 0.3, stratify = y_train_validation, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = feature_extraction.text.TfidfVectorizer(min_df=0)\n",
    "vectorizer1.fit(X_train_validation.values.astype('U'))\n",
    "X2_test = vectorizer1.transform(X_test.values.astype('U'))\n",
    "\n",
    "vectorizer2 = feature_extraction.text.TfidfVectorizer(min_df=0)\n",
    "vectorizer2.fit(X_train.values.astype('U'))\n",
    "X2_train = vectorizer2.transform(X_train.values.astype('U'))\n",
    "X2_validation = vectorizer2.transform(X_validation.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6673107108974641\n",
      "0.8814342738629093\n",
      "0.9202627546467723\n"
     ]
    }
   ],
   "source": [
    "X2_train_transformed = TransformToTensor(X2_train, 1200)\n",
    "X2_validation_transformed = TransformToTensor(X2_validation, 1200)\n",
    "X2_test_transformed = TransformToTensor(X2_test, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_test_transformed = pd.get_dummies(y_test).values\n",
    "y2_train_transformed = pd.get_dummies(y_train).values\n",
    "y2_validation_transformed = pd.get_dummies(y_validation).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kreiramo modele i zatim prikazujemo rezultate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1200, 32)          64000     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 88,962\n",
      "Trainable params: 88,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim = 2000, output_dim = 32, input_length = X2_train_transformed.shape[1]))\n",
    "model1.add(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model1.compile(optimizer = SGD(learning_rate = 0.0001), loss = CategoricalCrossentropy(), metrics = ['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "145/145 [==============================] - 178s 1s/step - loss: 0.6786 - accuracy: 0.5922 - val_loss: 0.6761 - val_accuracy: 0.5925\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 175s 1s/step - loss: 0.6764 - accuracy: 0.5922 - val_loss: 0.6760 - val_accuracy: 0.5925\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 182s 1s/step - loss: 0.6764 - accuracy: 0.5922 - val_loss: 0.6760 - val_accuracy: 0.5925\n",
      "Epoch 4/10\n",
      " 59/145 [===========>..................] - ETA: 1:41 - loss: 0.6749 - accuracy: 0.5964"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X2_train_transformed, y2_train_transformed, epochs=10, batch_size=32, validation_data=(X2_validation_transformed, y2_validation_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateModel(model1, X2_test_transformed, y2_test_transformed, history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = model1.predict_classes(X2_test_transformed, verbose=0)\n",
    "print(metrics.classification_report(np.argmax(y2_test_transformed, axis=1), p1))\n",
    "print(metrics.confusion_matrix(np.argmax(y2_test_transformed, axis=1), p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim = 2000, output_dim = 32, input_length = X2_train_transformed.shape[1]))\n",
    "model2.add(GRU(64))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer = Adam(learning_rate = 0.0001), loss = CategoricalCrossentropy(), metrics = ['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X2_train_transformed, y2_train_transformed, epochs=8, batch_size=32, validation_data=(X2_validation_transformed, y2_validation_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateModel(model2, X2_test_transformed, y2_test_transformed, history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = model2.predict_classes(X2_test_transformed, verbose=0)\n",
    "print(metrics.classification_report(np.argmax(y2_test_transformed, axis=1), p2))\n",
    "print(metrics.confusion_matrix(np.argmax(y2_test_transformed, axis=1), p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
